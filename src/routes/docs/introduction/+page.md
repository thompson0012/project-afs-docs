---
title: "Introduction"
---

# AFS — Memory Lake for Agentic AI

> **The memory layer AI agents actually want to use.**
>
> **Status:** Under active development. APIs and behaviors may change frequently.

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)


---

## The Problem: Agent Amnesia

```
┌────────────────────────────────────────────────────────────────┐
│  WITHOUT AFS                                                   │
│                                                                │
│  Day 1: Agent learns "API has rate limit 1000/hr"              │
│         └── Session ends → MEMORY LOST                         │
│                                                                │
│  Day 2: Same agent asks "What's the rate limit?"               │
│         └── "I don't know. Let me check..."                    │
│                                                                │
│  Agent-1 finds bug → Session ends → Agent-2 starts fresh       │
│                                                                │
│  Token budget exceeded → Old context truncated → Lost insights │
└────────────────────────────────────────────────────────────────┘
```

---

## The Solution: AFS Filesystem Memory

```
┌─────────────────────────────────────────────────────────────────┐
│  WITH AFS                                                       │
│                                                                 │
│  Day 1: Agent remembers "API rate limit: 1000/hr"               │
│         └── Stored in .afs/agents/my-agent/memories/            │
│                                                                 │
│  Day 2: Agent recalls "What do I know about rate limits?"       │
│         └── "API has limit of 1000/hr (from yesterday)"         │
│                                                                 │
│  Agent-1: Finds bug ──→ Shares to swarm ──→ Agent-2 knows it   │
│                                                                 │
│  Context compressed smartly ──→ Key insights preserved          │
└─────────────────────────────────────────────────────────────────┘
```

---

## Recording Agent Thinking (Reasoning Artifacts)

“When code is mostly generated by agents, how do we record the thinking process?”

AFS records **reasoning artifacts** (facts, insights, decisions), not hidden chain-of-thought:

- **Memories**: observations → reflections → knowledge units
- **Graph edges**: `similar_to`, `co_occurred`, `consolidated_from`, `depends_on`
- **Audit trail**: tamper-evident history of memory operations
- **Sessions**: conversation context under a token budget
- **Attachments**: evidence bound to memories (images, audio, structured data)

```
┌───────────────────────────────────────────────────────────────┐
│  AGENT THINKING → RECORDED AS ARTIFACTS                        │
│                                                               │
│  Decision / Evidence / Context                                │
│         ↓                                                     │
│  ┌──────────────┐   ┌──────────────┐   ┌───────────────────┐  │
│  │ Observation  │ → │ Reflection   │ → │ Knowledge Unit    │  │
│  └──────────────┘   └──────────────┘   └───────────────────┘  │
│         │                    │                   │           │
│         └── Graph edges (similar_to, depends_on, ...) ────────┘
│                                                               │
│  Audit trail (signed) + Session context (token-budgeted)       │
│                                                               │
└───────────────────────────────────────────────────────────────┘
```

---

## For AI Agents: Just Remember and Recall

You shouldn't need to think about databases. Just remember what you learn and recall it when needed.

```bash
# Remember what you discovered
afs memory create --agent-id researcher-1 \
  --content "Found SQL injection in login endpoint" \
  --type observation \
  --importance 0.9

# Later, recall relevant context  
afs query search --agent-id researcher-1 --query "security vulnerabilities"

# Share with your team
afs memory share --agent-id researcher-1 \
  --memory-id <id> \
  --swarm-id security-team
```

Or use Python when you need more control:

```python
from afs import MemoryEngine, MemoryCreateRequest

# Remember
memory = engine.remember(MemoryCreateRequest(
    agent_id="researcher-1",
    content="Auth module has race condition",
    memory_type="observation",
))

# Recall
results = engine.search("researcher-1", "auth vulnerabilities")
```

---

## Three-Tier Memory (Automatic)

AFS manages memory like human cognition. You just store—AFS handles the rest.

```
                    AUTO-MIGRATION FLOW
                    
   ┌─────────────────┐
   │  WORKING MEMORY │  Recent discoveries (< 24h)
   │   (active use)  │  • Fast access
   └────────┬────────┘  • No compression
            │
            │ After 24h or consolidation trigger
            ▼
   ┌─────────────────┐
   │ EPISODIC MEMORY │  Complete experience history
   │   (archived)    │  • Full provenance
   └────────┬────────┘  • Searchable
            │
            │ Pattern detected → Auto-synthesis
            ▼
   ┌─────────────────┐
   │ SEMANTIC MEMORY │  Consolidated knowledge
   │  (insights)     │  • "Users prefer dark mode"
   └─────────────────┘  • "API limit is 1000/hr"
```

**You store observations. AFS extracts knowledge.**

---

## Knowledge Graph (Auto-Discovered)

Memories connect automatically. No manual linking required.

```
   ┌──────────────┐      similar_to       ┌──────────────┐
   │  "SQL inj    │◄─────────────────────►│  "Auth bug   │
   │  in login"   │                       │  in token"   │
   └──────┬───────┘                       └───────┬──────┘
          │                                       │
          │ consolidated_from                     │ co_occurred
          │ (AFS synthesized)                     │ (same session)
          ▼                                       ▼
   ┌──────────────┐                       ┌──────────────┐
   │ KNOWLEDGE:   │                       │ "Rate limit  │
   │ "Login sys   │                       │ bypass found"│
   │ vulnerable"  │                       └──────────────┘
   └──────────────┘
```

```bash
# AFS discovers these links automatically
afs graph mine --agent-id researcher-1
afs graph neighbors --agent-id researcher-1 --memory-id <id>
```

---

## Multi-Agent Knowledge Sharing

Agents share discoveries through the swarm.

```
   AGENT-1 (Security Scanner)          AGENT-2 (Report Writer)
   ┌─────────────────────┐              ┌─────────────────────┐
   │ Discovers:          │              │ Needs to know:      │
   │ "Critical vuln in   │              │ "What did we find?" │
   │  payment module"    │              └──────────┬──────────┘
   └──────────┬──────────┘                         │
              │ afs memory share                   │ afs query search
              │ --swarm-id security-team           │ --swarm-id security-team
              ▼                                    ▼
   ┌─────────────────────────────────────────────────────────────┐
   │                    SHARED SWARM POOL                        │
   │                                                             │
   │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
   │  │ Memory 1     │  │ Memory 2     │  │ Memory 3     │      │
   │  │ (from Agent-1)│  │ (from Agent-3)│  │ (from Agent-1)│      │
   │  └──────────────┘  └──────────────┘  └──────────────┘      │
   │                                                             │
   └─────────────────────────────────────────────────────────────┘
```

---

## Session Context Management

Track conversations without blowing token budgets.

```
   SESSION: "code-review-assistant"
   Token Budget: 4000
   
   Turn 1: User    ──→ "Review this function"    [uncompressed]
   Turn 2: Agent   ──→ "Found 3 issues..."       [uncompressed]
   Turn 3: User    ──→ "What about line 42?"     [uncompressed]
   Turn 4: Agent   ──→ "That's a bug..."         [uncompressed]
   ... (more turns)
   Turn 15: User   ──→ "Explain the first bug"   
   
   AUTO-COMPRESSION:
   ┌─────────────────────────────────────────────┐
   │ Recent (Turns 12-15): Full text             │
   │                                             │
   │ Older (Turns 1-11): Summarized              │
   │ "Discussed authentication bugs,             │
   │  rate limiting issues, and SQL injection"   │
   └─────────────────────────────────────────────┘
   
   Total tokens: 3,847 / 4,000 ✓
```

```bash
afs session create --agent-id assistant --token-budget 4000
afs session add-turn --session-id <id> --role user --content "Analyze this"
afs session context --session-id <id>  # Returns compressed context
```

---

## Multi-Modal Attachments

Link evidence to memories.

```
   MEMORY: "Found vulnerability in login"
   
   ATTACHMENTS:
   ┌──────────────┐  ┌──────────────┐  ┌──────────────┐
   │  exploit.png │  │  payload.json│  │  proof.mp3   │
   │   [image]    │  │ [structured] │  │   [audio]    │
   └──────────────┘  └──────────────┘  └──────────────┘
          │                  │                  │
          └──────────────────┼──────────────────┘
                             │
                    AFS extracts metadata:
                    • Image: dimensions, EXIF, perceptual hash
                    • JSON: schema, row count
                    • Audio: Whisper transcription
```

```bash
afs attachment upload --agent-id researcher-1 \
  --file exploit-proof.png \
  --type image \
  --memory-id <memory-id>
```

---

## Common Agentic Use Cases (AFS Solves 80% of These)

### 1. Codebase Analysis Agent

**The Problem:**
```
WITHOUT AFS:
┌─────────────────────────────────────────────────────────────┐
│ Session 1: Agent analyzes /src/auth module                   │
│   └── Learns: "Uses JWT tokens, 24h expiry"                  │
│   └── Session ends → ALL LOST                                │
│                                                             │
│ Session 2: User asks "How does auth work?"                   │
│   └── Agent: "Let me analyze the auth module..."             │
│   └── RE-ANALYZES same code (wasted work)                    │
└─────────────────────────────────────────────────────────────┘
```

**AFS Solution:**
```
WITH AFS:
┌─────────────────────────────────────────────────────────────┐
│ Session 1: Agent analyzes /src/auth                          │
│   └── Remembers: "JWT tokens, 24h expiry"                    │
│   └── Stores in: .afs/agents/coder-agent/memories/           │
│                                                             │
│ Session 2: User asks "How does auth work?"                   │
│   └── Agent recalls: "JWT tokens with 24h expiry"            │
│   └── No re-analysis needed ✓                                │
│                                                             │
│ Day 3: Analysis consolidated into knowledge:                 │
│   └── "Auth system uses JWT pattern across all services"     │
└─────────────────────────────────────────────────────────────┘
```

```bash
# Agent remembers findings
afs memory create --agent-id coder-agent \
  --content "Auth module: JWT tokens, 24h expiry, refresh endpoint at /auth/refresh" \
  --type observation

# Later, recalls relevant context
afs query search --agent-id coder-agent --query "authentication implementation"
```

---

### 2. Security Research Team

**The Problem:**
```
WITHOUT AFS:
┌─────────────────────────────────────────────────────────────┐
│ Agent-1 (Scanner): Finds SQL injection in /api/users        │
│   └── Documents in memory...                                 │
│   └── Session ends → Finding lost                           │
│                                                             │
│ Agent-2 (Writer): Writing security report                    │
│   └── "No critical vulnerabilities found"                    │
│   └── MISSES the SQL injection                              │
└─────────────────────────────────────────────────────────────┘
```

**AFS Solution:**
```
WITH AFS:
┌─────────────────────────────────────────────────────────────┐
│ Agent-1 (Scanner): Finds SQL injection                       │
│   └── afs memory create --agent-id scanner-1 ...             │
│   └── afs memory share --swarm-id security-team              │
│                                                             │
│ SHARED SWARM POOL:                                          │
│   ┌─────────────────────────────────────────────┐           │
│   │ "SQL injection in /api/users"               │           │
│   │ "XSS vulnerability in comments"             │           │
│   │ "Rate limiting bypass found"                │           │
│   └─────────────────────────────────────────────┘           │
│                                                             │
│ Agent-2 (Writer): Queries swarm knowledge                    │
│   └── afs query search --swarm-id security-team              │
│   └── "Found 3 critical: SQLi, XSS, bypass"                  │
│   └── Report is accurate ✓                                   │
└─────────────────────────────────────────────────────────────┘
```

---

### 3. Customer Support Agent

**The Problem:**
```
WITHOUT AFS:
┌─────────────────────────────────────────────────────────────┐
│ Ticket #1: Customer reports "Login not working"              │
│   └── Agent investigates → Finds it's a cookie issue         │
│   └── Resolves ticket                                        │
│                                                             │
│ Ticket #2: Same customer, same issue next week               │
│   └── NEW agent handles it                                   │
│   └── "Have you tried clearing cookies?"                     │
│   └── Customer frustrated: "You said that last time!"        │
└─────────────────────────────────────────────────────────────┘
```

**AFS Solution:**
```
WITH AFS:
┌─────────────────────────────────────────────────────────────┐
│ Ticket #1: Cookie issue resolved                             │
│   └── afs memory create --agent-id support-1                 │
│       --content "Customer-123: Cookie issue, cleared, OK"    │
│                                                             │
│ Ticket #2: Same customer returns                             │
│   └── afs query search --agent-id support-2                  │
│       --query "Customer-123 login issues"                    │
│   └── "Previous fix: cookie clearing. Escalating..."         │
│   └── Context preserved across agents ✓                      │
└─────────────────────────────────────────────────────────────┘
```

---

### 4. Long-Running Research Task

**The Problem:**
```
WITHOUT AFS:
┌─────────────────────────────────────────────────────────────┐
│ Day 1: Agent reads 50 papers                                 │
│   └── Extracts 200 key findings                              │
│   └── Token budget exceeded → Truncates context              │
│                                                             │
│ Day 2: Agent continues research                              │
│   └── "What were yesterday's key insights?"                  │
│   └── "Sorry, I can only see last 3 papers..."               │
│   └── Lost 80% of progress                                   │
└─────────────────────────────────────────────────────────────┘
```

**AFS Solution:**
```
WITH AFS:
┌─────────────────────────────────────────────────────────────┐
│ Day 1: Agent reads 50 papers                                 │
│   └── Each finding: afs memory create                        │
│   └── Day 1 insights stored ✓                               │
│                                                             │
│ NIGHT: Scheduler auto-consolidates                          │
│   └── 200 observations → 15 knowledge units                  │
│   └── "Theme: Transformer architectures dominate"            │
│                                                             │
│ Day 2: Agent continues                                       │
│   └── afs query search "key themes from yesterday"           │
│   └── Gets consolidated summary, not raw data                │
│   └── Builds on Day 1 knowledge ✓                           │
└─────────────────────────────────────────────────────────────┘
```

---

### 5. Multi-Agent Workflow (Research → Write)

**The Problem:**
```
WITHOUT AFS:
┌─────────────────────────────────────────────────────────────┐
│ Phase 1: Research Agent                                      │
│   └── Discovers: 10 key insights about market trends         │
│   └── Writes to file: "research_notes.txt"                   │
│                                                             │
│ Phase 2: Writing Agent                                       │
│   └── Opens research_notes.txt                               │
│   └── "These notes are disorganized..."                      │
│   └── Misses 3 critical insights                             │
│                                                             │
│ Result: Report incomplete, insights scattered               │
└─────────────────────────────────────────────────────────────┘
```

**AFS Solution:**
```
WITH AFS:
┌─────────────────────────────────────────────────────────────┐
│ Phase 1: Research Agent                                      │
│   └── Discovers insights                                     │
│   └── Stores in AFS with importance scores                   │
│   └── afs memory consolidate → Synthesized knowledge         │
│                                                             │
│ HANDOFF: Research → Writing                                  │
│   └── Writing agent queries:                                 │
│       afs query search "market trends" --limit 10            │
│   └── Gets top 10 most important, consolidated insights      │
│                                                             │
│ Result: Report uses all critical findings ✓                 │
└─────────────────────────────────────────────────────────────┘
```

```bash
# Research agent stores findings
afs memory create --agent-id researcher \
  --content "Market trend: AI adoption up 300% in healthcare" \
  --type observation \
  --importance 0.95

# Consolidate into knowledge
afs memory consolidate --agent-id researcher

# Writing agent retrieves
afs query search --agent-id writer \
  --query "market trends AI healthcare" \
  --limit 5
```

---

### 6. Documentation Agent with Context

**The Problem:**
```
WITHOUT AFS:
┌─────────────────────────────────────────────────────────────┐
│ Agent writes API docs for 50 endpoints                       │
│   └── Endpoint 1-10: Remembers auth pattern                  │
│   └── Endpoint 11-20: Forgets auth details                   │
│   └── Endpoint 21+: Inconsistent documentation               │
│                                                             │
│ Result: Some docs mention Bearer token, some don't          │
└─────────────────────────────────────────────────────────────┘
```

**AFS Solution:**
```
WITH AFS:
┌─────────────────────────────────────────────────────────────┐
│ Agent creates semantic knowledge first:                      │
│   └── "All endpoints use Bearer token auth"                  │
│   └── "Rate limit: 1000 req/hr across all APIs"              │
│                                                             │
│ Writing each endpoint:                                       │
│   └── afs query search "auth pattern for this endpoint"      │
│   └── Consistently applies Bearer token to all 50 docs       │
│                                                             │
│ Result: Consistent, accurate documentation ✓                │
└─────────────────────────────────────────────────────────────┘
```

---

## Summary: AFS Solves These 80% Issues

| Use Case | Without AFS | With AFS |
|----------|-------------|----------|
| **Code Analysis** | Re-analyze same code every session | Remember analysis forever |
| **Security Teams** | Findings lost between agents | Shared swarm knowledge |
| **Customer Support** | No customer history | Full context across agents |
| **Long Research** | Token limits truncate insights | Consolidated knowledge grows |
| **Multi-Agent** | Handoff loses critical info | Smooth knowledge transfer |
| **Documentation** | Inconsistent patterns | Semantic knowledge guides |

**Common thread:** Without AFS, agents repeat work, lose context, and miss insights. With AFS, they build on past learning.

---

## Quick Start

### Install

```bash
pip install afs
```

### Initialize

```bash
afs init
# Creates .afs/ with full structure
```

### CLI (What Agents Use)

```bash
# Core operations
afs memory create --agent-id my-agent --content "Key insight"
afs query search --agent-id my-agent --query "insight"
afs memory consolidate --agent-id my-agent

# Sessions
afs session create --agent-id my-agent --token-budget 4000
afs session add-turn --session-id <id> --role user --content "Hello"
afs session context --session-id <id>

# Graph
afs graph mine --agent-id my-agent
afs graph neighbors --agent-id my-agent --memory-id <id>

# Maintenance
afs scheduler start
```

### Python API (For Complex Workflows)

```python
from pathlib import Path
from afs.config import MemorySystemSettings
from afs.engine import MemoryEngine
from afs.models import MemoryCreateRequest

base_path = Path("./.afs")
settings = MemorySystemSettings(base_path=base_path)
engine = MemoryEngine(base_path, settings)

memory = engine.remember(MemoryCreateRequest(
    agent_id="my-agent",
    content="Important finding",
    memory_type="observation",
))

results = engine.search("my-agent", "findings")
engine.consolidate("my-agent")
```

---

## Architecture

```
.afs/
├── config.yaml               # Single YAML configuration
├── agents/
│   └── {agent_id}/
│       ├── memories/
│       │   ├── working/      # Recent (< 24h)
│       │   ├── episodic/     # Experience history
│       │   └── semantic/     # Knowledge (consolidated)
│       ├── indices/
│       │   ├── text/         # FTS5 full-text index
│       │   ├── vector/       # HNSW embeddings index
│       │   ├── temporal/     # Time-based index
│       │   └── graph/        # Memory relationships
│       └── attachments/      # Binary files
├── sessions/                 # Conversation history
└── system/
    └── logs/audit/          # Signed operation logs
```

**Storage:** JSON files + SQLite FTS5 + HNSW indices + msgpack graph edges

---

## Configuration

`.afs/config.yaml`:

```yaml
version: 1

# Embeddings (sine = hash-based, zero deps)
embedding_provider: "sine"
embedding_dimension: 1024

# Background maintenance (opt-in)
scheduler_enabled: false
scheduler_lifecycle_tick_interval: 3600
scheduler_consolidation_interval: 86400

# Session compression
compression_keep_recent: 4
compression_min_turns: 6

# Search strategy
search_strategy: "fts"  # or "rrf" for hybrid
```

## Instance discovery and configuration location

AFS enforces a single configuration location: the file at `{base_path}`/config.yaml. By default the CLI and Python API discover the instance by walking parent directories from the current working directory until they find a directory named .afs containing config.yaml. The discovered directory is used as the base_path for all operations.

If you need to operate against a different instance, override the discovered base path with the --base-path option (CLI) or by passing base_path to the Python API (MemorySystemSettings or MemoryEngine). Example:

```bash
afs --base-path /path/to/.afs memory create --agent-id my-agent --content "Key insight"
```

The CLI no longer supports specifying an arbitrary config file path. AFS does not accept arbitrary config file locations; the single source of truth is `{base_path}`/config.yaml.

The configuration schema and field descriptions shown above remain unchanged. Only the lookup location and discovery behavior are enforced.

---

## Audit Logging

AFS provides comprehensive audit logging of all operations for security, compliance, and debugging purposes.

### Key Features

**Fail-Open Policy**: Audit failures never break primary operations. If audit logging fails, the operation continues and the failure is logged to standard logging.

**Attempt Logging**: Both successful and failed operations are audited:
- `status="success"`: Operation completed successfully
- `status="error"`: Operation failed (includes `error_type` and `error_message`)
- `status="partial"`: Some items succeeded, some failed (batch operations)

**Standardized Operation Names**: All audit records use consistent operation names from `afs.audit_taxonomy`:

```python
from afs.audit_taxonomy import (
    OPERATION_CREATE_MEMORY,
    OPERATION_SEARCH_MEMORY,
    OPERATION_GET_ATTACHMENT,
    # ... 45 standardized operations
)
```

**Payload Conventions**: Audit records include operation-specific context:

Memory operations:
- `payload["query"]`: Search/recall query text
- `payload["filters"]`: Filter criteria for list operations
- `payload["count"]`: Number of results affected

Graph operations:
- `payload["source_id"]`, `payload["target_id"]`: Memory IDs for edge operations
- `payload["edge_type"]`: Relationship type
- `payload["depth"]`: Search depth for path queries

Session/Swarm operations:
- `payload["session_id"]`, `payload["swarm_id"]`: Resource identifiers
- `payload["role"]`: user/assistant/system (for session turns)
- `payload["shared_memory_ids"]`: Memory IDs being shared

### What Is NOT Audited

**Audit-log reads themselves are not audited** to avoid recursion and noise:
- Queries to `/admin/audit` API endpoint
- Direct calls to `AuditLog.query_records()`

**Streaming downloads**: Audit records reflect successful retrieval from storage. Mid-stream client disconnects are not treated as audit failures.

### Audit Record Structure

```json
{
  "id": "audit_1708196400000_a3f2",
  "timestamp": "2026-02-17T14:00:00Z",
  "operation": "search_memory",
  "operator": "agent-123",
  "resource": null,
  "status": "success",
  "payload": {
    "query": "security vulnerabilities",
    "filters": {"importance": {"$gte": 0.8}},
    "count": 15
  }
}
```

Error example:
```json
{
  "id": "audit_1708196401000_b7c1",
  "timestamp": "2026-02-17T14:00:01Z",
  "operation": "retrieve_memory",
  "operator": "agent-456",
  "resource": "mem_nonexistent",
  "status": "error",
  "error_type": "not_found",
  "error_message": "Memory mem_nonexistent not found"
}
```

### Querying Audit Logs

```bash
# CLI
afs admin audit --agent-id agent-123 --operation search_memory --limit 10

# API
GET /admin/audit?agent_id=agent-123&operation=search_memory&limit=10
```

For full operation taxonomy and payload conventions, see `src/afs/audit_taxonomy.py`.

---

## Use Cases

- **Code Analysis Agents**, remember codebase patterns across sessions
- **Security Research Teams**, share vulnerability findings between agents
- **Multi-Agent Workflows**, research agent → Writing agent handoff
- **Long-Running Tasks**, accumulate insights over days/weeks
- **Compliance and Security**, audit trail of all agent decisions
- **Offline Environments**, works without internet or cloud

---

## Integration Patterns

### With CrewAI

```python
from crewai import Agent

researcher = Agent(
    role="Security Researcher",
    tools=[
        lambda content: afs_cli("memory", "create", agent_id="researcher", content=content),
        lambda query: afs_cli("query", "search", agent_id="researcher", query=query),
    ]
)
```

### With LangGraph

```python
memory = engine.remember(MemoryCreateRequest(
    agent_id=state["agent_id"],
    content=node_result,
    memory_type="observation",
))
```

### With AutoGen

```python
swarm_manager.share_memory(
    swarm_id="security-team",
    agent_id="scanner-1",
    memory_id=memory.memory_id,
    engine=engine,
)
```

---

## Performance

| Metric | Value |
|--------|-------|
| Concurrent agents | 100+ (file-locking) |
| Search latency | &lt; 100ms (HNSW + FTS5) |
| Memory capacity | Limited by filesystem (tested 100k+) |
| Batch operations | Atomic (all-or-nothing) |

---

## API Server

For non-Python agents:

```bash
afs-server  # localhost:8080
```

Interactive docs at `http://localhost:8080/docs`

---

## When to Use AFS

**✅ Good fit:**
- AI agents that need to remember across sessions
- Multi-agent systems sharing knowledge
- Long-running tasks with evolving context
- Offline/air-gapped environments
- Compliance-sensitive applications

**❌ Not a fit:**
- Stateless single-prompt agents (overkill)
- Real-time collaborative editing
- Sub-millisecond latency requirements

---

## Installation Options

```bash
# Core (zero dependencies)
pip install afscli

# With OpenAI embeddings
pip install afscli[embeddings]

# With image processing
pip install afscli[vision]

# With audio transcription
pip install afscli[transcribe]
```

---

## Development

```bash
git clone https://github.com/labs21/afs.git
cd afs
pip install -e ".[dev]"
pytest tests/
```


---

**AFS**: The memory layer AI agents actually want to use.
